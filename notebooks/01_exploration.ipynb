{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Warehouse Environment Exploration\n",
    "# This notebook demonstrates the autonomous parcel routing environment\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for development\n",
    "project_root = Path.cwd().parent\n",
    "src_dir = project_root / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Ready to explore the enhanced warehouse environment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e068ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the enhanced APR modules\n",
    "from apr import WarehouseEnv\n",
    "from apr.utils import render_env\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "print(\"APR modules imported successfully!\")\n",
    "\n",
    "# Create the enhanced warehouse environment\n",
    "env = WarehouseEnv(seed=42)\n",
    "print(f\"\\n Created warehouse environment:\")\n",
    "print(f\"   Size: {env.n_rows}x{env.n_cols}\")\n",
    "print(f\"   Packages: {len(env.package_positions_initial)}\")\n",
    "print(f\"   Shelves: {len(env.shelf_positions)}\")\n",
    "print(f\"   Max steps: {env.max_steps}\")\n",
    "\n",
    "# Reset and show initial state\n",
    "state = env.reset()\n",
    "print(f\"\\n Environment reset. Initial state: {state}\")\n",
    "env.print_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ac4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the environment with different rendering modes\n",
    "\n",
    "print(\" Environment Visualization Modes:\")\n",
    "print(\"\\n1. Console ASCII rendering:\")\n",
    "env.render(mode=\"human\")\n",
    "\n",
    "print(\"\\n2. Rich sprite-based rendering:\")\n",
    "try:\n",
    "    env.render(mode=\"sprites\")\n",
    "except Exception as e:\n",
    "    print(f\"Sprite rendering failed: {e}\")\n",
    "    print(\"Falling back to matplotlib rendering...\")\n",
    "    env.render(mode=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57wtxd90kt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate package pickup and delivery mechanics\n",
    "\n",
    "print(\" Package Pickup & Delivery Demo\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Reset environment\n",
    "env.reset()\n",
    "total_reward = 0\n",
    "\n",
    "# Manual sequence to demonstrate mechanics\n",
    "print(\"\\n Starting position:\")\n",
    "env.print_state()\n",
    "\n",
    "# Move right to pickup first package at (0,1)\n",
    "print(\"\\n  Moving right to pickup package...\")\n",
    "next_state, reward, done, info = env.step(3)  # right\n",
    "total_reward += reward\n",
    "print(f\"Reward: {reward} | Info: {info}\")\n",
    "env.render(mode=\"human\")\n",
    "\n",
    "# Try to pickup another package at (1,2)\n",
    "print(\"\\n  Moving down...\")\n",
    "next_state, reward, done, info = env.step(1)  # down\n",
    "total_reward += reward\n",
    "print(f\"Reward: {reward} | New position: {next_state}\")\n",
    "\n",
    "print(\"\\n  Moving right to (1,2)...\")\n",
    "next_state, reward, done, info = env.step(3)  # right\n",
    "total_reward += reward\n",
    "print(f\"Reward: {reward} | Info: {info}\")\n",
    "env.render(mode=\"human\")\n",
    "\n",
    "print(f\"\\nðŸ’° Total reward so far: {total_reward}\")\n",
    "print(f\" Packages collected: {env.num_picked_up_items}\")\n",
    "print(f\" Packages remaining: {len(env.packages_remaining)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9u0ta6evmnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the training pipeline with enhanced environment\n",
    "\n",
    "print(\" Training Pipeline Test\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Import training modules\n",
    "from apr.train import main\n",
    "import sys\n",
    "\n",
    "# Set up arguments for a short training run\n",
    "original_argv = sys.argv.copy()\n",
    "sys.argv = [\"train.py\", \"--config\", \"cfg/baseline.yaml\"]\n",
    "\n",
    "print(\"Starting training with enhanced environment...\")\n",
    "print(\"(This will run for 1000 episodes)\")\n",
    "\n",
    "try:\n",
    "    main()\n",
    "    print(\" Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\" Training failed: {e}\")\n",
    "finally:\n",
    "    sys.argv = original_argv  # Restore original arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixcj4fn0fg9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training results\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\" Training Results Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find the latest training run\n",
    "outputs_dir = Path(\"../outputs/runs\")\n",
    "if outputs_dir.exists():\n",
    "    run_dirs = [d for d in outputs_dir.iterdir() if d.is_dir()]\n",
    "    if run_dirs:\n",
    "        latest_run = max(run_dirs, key=lambda x: x.stat().st_mtime)\n",
    "        print(f\" Latest run: {latest_run.name}\")\n",
    "        \n",
    "        # Load and plot metrics\n",
    "        metrics_file = latest_run / \"metrics.csv\"\n",
    "        if metrics_file.exists():\n",
    "            df = pd.read_csv(metrics_file)\n",
    "            \n",
    "            # Plot reward curve\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(df['episode'], df['reward'])\n",
    "            plt.title('Training Rewards Over Episodes')\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Reward')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(df['episode'], df['epsilon'])\n",
    "            plt.title('Epsilon Decay Over Episodes')\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Epsilon')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary stats\n",
    "            print(f\"\\n Training Summary:\")\n",
    "            print(f\"   Final reward: {df['reward'].iloc[-1]:.1f}\")\n",
    "            print(f\"   Average reward (last 100): {df['reward'].tail(100).mean():.1f}\")\n",
    "            print(f\"   Max reward: {df['reward'].max():.1f}\")\n",
    "            print(f\"   Final epsilon: {df['epsilon'].iloc[-1]:.3f}\")\n",
    "        else:\n",
    "            print(\"NOTFOUND: No metrics file found\")\n",
    "    else:\n",
    "        print(\"NOTFOUND: No training runs found\")\n",
    "else:\n",
    "    print(\"NOTFOUND: Outputs directory not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".apr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
